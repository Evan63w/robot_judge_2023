{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW06: ML and Causal Inference (due November 9th)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: Double Machine learning with Lasso\n",
    "\n",
    "In this exercise you will investigate a research question similar to the one in HW02. Namely, what is the effect of being in a Union on wages? You will use the same data as in HW02 (description of the variables can be found [here](https://rdrr.io/rforge/sampleSelection/man/nlswork.html)). Although, here instead of just including controls, you will estimate the effect of union membership on wages using double Lasso.\n",
    "\n",
    "The regression of reference is the following: \n",
    "\n",
    "$$ln\\_wage_i = \\beta_0 + \\beta_1 union_i +\\varepsilon_i$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data (NLSY)\n",
    "df = pd.read_stata('http://www.stata-press.com/data/r16/nlswork.dta')\n",
    "df = df.dropna()\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idcode</th>\n",
       "      <th>year</th>\n",
       "      <th>birth_yr</th>\n",
       "      <th>age</th>\n",
       "      <th>race</th>\n",
       "      <th>msp</th>\n",
       "      <th>nev_mar</th>\n",
       "      <th>grade</th>\n",
       "      <th>collgrad</th>\n",
       "      <th>not_smsa</th>\n",
       "      <th>...</th>\n",
       "      <th>south</th>\n",
       "      <th>ind_code</th>\n",
       "      <th>occ_code</th>\n",
       "      <th>union</th>\n",
       "      <th>wks_ue</th>\n",
       "      <th>ttl_exp</th>\n",
       "      <th>tenure</th>\n",
       "      <th>hours</th>\n",
       "      <th>wks_work</th>\n",
       "      <th>ln_wage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>20.0</td>\n",
       "      <td>black</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.256410</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.589977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>77</td>\n",
       "      <td>51</td>\n",
       "      <td>25.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.775641</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>1.778681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>80</td>\n",
       "      <td>51</td>\n",
       "      <td>28.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.294872</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>45.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2.551715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "      <td>51</td>\n",
       "      <td>33.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.160256</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>42.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2.614172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>87</td>\n",
       "      <td>51</td>\n",
       "      <td>35.0</td>\n",
       "      <td>black</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.987180</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>45.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2.536374</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   idcode  year  birth_yr   age   race  msp  nev_mar  grade  collgrad  \\\n",
       "0       1    72        51  20.0  black  1.0      0.0   12.0         0   \n",
       "1       1    77        51  25.0  black  0.0      0.0   12.0         0   \n",
       "2       1    80        51  28.0  black  0.0      0.0   12.0         0   \n",
       "3       1    85        51  33.0  black  0.0      0.0   12.0         0   \n",
       "4       1    87        51  35.0  black  0.0      0.0   12.0         0   \n",
       "\n",
       "   not_smsa  ...  south  ind_code  occ_code  union  wks_ue   ttl_exp  \\\n",
       "0       0.0  ...    0.0       4.0       6.0    1.0     0.0  2.256410   \n",
       "1       0.0  ...    0.0      12.0       8.0    0.0     0.0  3.775641   \n",
       "2       0.0  ...    0.0       5.0       6.0    1.0     0.0  5.294872   \n",
       "3       0.0  ...    0.0       5.0       6.0    1.0     0.0  7.160256   \n",
       "4       0.0  ...    0.0       5.0       6.0    1.0     0.0  8.987180   \n",
       "\n",
       "     tenure  hours  wks_work   ln_wage  \n",
       "0  0.916667   40.0      51.0  1.589977  \n",
       "1  1.500000   32.0      52.0  1.778681  \n",
       "2  1.833333   45.0      75.0  2.551715  \n",
       "3  1.916667   42.0      97.0  2.614172  \n",
       "4  3.916667   45.0      95.0  2.536374  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "Y = df['ln_wage']\n",
    "D = df['union']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                      Y   R-squared:                       0.052\n",
      "Model:                            OLS   Adj. R-squared:                  0.052\n",
      "Method:                 Least Squares   F-statistic:                     741.9\n",
      "Date:                Tue, 07 Nov 2023   Prob (F-statistic):          4.56e-159\n",
      "Time:                        20:13:34   Log-Likelihood:                -8266.7\n",
      "No. Observations:               13452   AIC:                         1.654e+04\n",
      "Df Residuals:                   13450   BIC:                         1.655e+04\n",
      "Df Model:                           1                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      1.6564      0.004    377.147      0.000       1.648       1.665\n",
      "D              0.2502      0.009     27.238      0.000       0.232       0.268\n",
      "==============================================================================\n",
      "Omnibus:                      425.572   Durbin-Watson:                   1.032\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              895.660\n",
      "Skew:                           0.205   Prob(JB):                    3.24e-195\n",
      "Kurtosis:                       4.196   Cond. No.                         2.53\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model = smf.ols('Y ~ D', data=D)\n",
    "res = model.fit()\n",
    "print(res.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**What could be potential sources of bias (i.e. confounders)?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some confounders could include age and occupation code. These are confounders because they can impact both the treatment and the outcome. For example, younger people have had less time to join a union and may be predisposed towards certain types of jobs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in X with all predictors that are not colliders\n",
    "X_cat = df[['year', \"race\", \"msp\", \"nev_mar\",\"not_smsa\",\"c_city\",\"south\",'union']]\n",
    "X_cont = df[[\"age\", \"wks_ue\",\"tenure\",\"hours\",\"wks_work\",]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "\n",
    "X_cat_columns = X_cat.columns\n",
    "X_cat = encoder.fit_transform(X_cat)\n",
    "X_cat = X_cat.astype('float32')\n",
    "X_cat = pd.DataFrame(X_cat, columns=X_cat_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "# TODO: standardize all continuous variable in X to variance one\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_cont_st = scaler.fit_transform(X_cont)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>race</th>\n",
       "      <th>msp</th>\n",
       "      <th>nev_mar</th>\n",
       "      <th>not_smsa</th>\n",
       "      <th>c_city</th>\n",
       "      <th>south</th>\n",
       "      <th>union</th>\n",
       "      <th>age</th>\n",
       "      <th>wks_ue</th>\n",
       "      <th>tenure</th>\n",
       "      <th>hours</th>\n",
       "      <th>wks_work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.916667</td>\n",
       "      <td>40.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>32.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.833333</td>\n",
       "      <td>45.0</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>42.0</td>\n",
       "      <td>97.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.916667</td>\n",
       "      <td>45.0</td>\n",
       "      <td>95.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13447</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13448</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>39.0</td>\n",
       "      <td>47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13449</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13450</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13451</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.416667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>79.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>13452 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  race  msp  nev_mar  not_smsa  c_city  south  union   age  wks_ue  \\\n",
       "0       2.0   0.0  1.0      0.0       0.0     1.0    0.0    1.0  20.0     0.0   \n",
       "1       4.0   0.0  0.0      0.0       0.0     1.0    0.0    0.0  25.0     0.0   \n",
       "2       6.0   0.0  0.0      0.0       0.0     1.0    0.0    1.0  28.0     0.0   \n",
       "3       9.0   0.0  0.0      0.0       0.0     1.0    0.0    1.0  33.0     0.0   \n",
       "4      10.0   0.0  0.0      0.0       0.0     0.0    0.0    1.0  35.0     0.0   \n",
       "...     ...   ...  ...      ...       ...     ...    ...    ...   ...     ...   \n",
       "13447   4.0   0.0  1.0      0.0       0.0     1.0    1.0    0.0  32.0     0.0   \n",
       "13448   5.0   0.0  1.0      0.0       0.0     1.0    1.0    1.0  33.0     0.0   \n",
       "13449   8.0   0.0  0.0      0.0       0.0     1.0    1.0    1.0  38.0     0.0   \n",
       "13450   9.0   0.0  0.0      0.0       0.0     1.0    1.0    1.0  40.0     0.0   \n",
       "13451  11.0   0.0  0.0      0.0       0.0     1.0    1.0    1.0  43.0     0.0   \n",
       "\n",
       "         tenure  hours  wks_work  \n",
       "0      0.916667   40.0      51.0  \n",
       "1      1.500000   32.0      52.0  \n",
       "2      1.833333   45.0      75.0  \n",
       "3      1.916667   42.0      97.0  \n",
       "4      3.916667   45.0      95.0  \n",
       "...         ...    ...       ...  \n",
       "13447  2.083333   40.0      52.0  \n",
       "13448  3.000000   39.0      47.0  \n",
       "13449  8.000000   38.0      56.0  \n",
       "13450  0.000000   40.0      52.0  \n",
       "13451  3.416667   38.0      79.0  \n",
       "\n",
       "[13452 rows x 13 columns]"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# join all Xs\n",
    "X = pd.merge(X_cat, X_cont, left_index=True, right_index=True)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: generate train/test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>race</th>\n",
       "      <th>msp</th>\n",
       "      <th>nev_mar</th>\n",
       "      <th>not_smsa</th>\n",
       "      <th>c_city</th>\n",
       "      <th>south</th>\n",
       "      <th>union</th>\n",
       "      <th>age</th>\n",
       "      <th>wks_ue</th>\n",
       "      <th>tenure</th>\n",
       "      <th>hours</th>\n",
       "      <th>wks_work</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9133</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12033</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.083333</td>\n",
       "      <td>40.0</td>\n",
       "      <td>69.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11515</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>40.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7077</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>40.0</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1886</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>54.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5191</th>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13418</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>40.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.416667</td>\n",
       "      <td>40.0</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>38.0</td>\n",
       "      <td>52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>49.0</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10761 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       year  race  msp  nev_mar  not_smsa  c_city  south  union   age  wks_ue  \\\n",
       "9133   11.0   0.0  0.0      0.0       0.0     0.0    1.0    0.0  40.0     0.0   \n",
       "12033  11.0   0.0  0.0      0.0       0.0     1.0    1.0    0.0  35.0     0.0   \n",
       "11515   7.0   2.0  1.0      0.0       0.0     0.0    1.0    0.0  31.0    40.0   \n",
       "7077    3.0   0.0  0.0      1.0       0.0     1.0    1.0    1.0  20.0     0.0   \n",
       "1886    5.0   2.0  1.0      0.0       0.0     0.0    0.0    1.0  28.0     0.0   \n",
       "...     ...   ...  ...      ...       ...     ...    ...    ...   ...     ...   \n",
       "5191    2.0   2.0  1.0      0.0       0.0     1.0    0.0    1.0  24.0     0.0   \n",
       "13418   1.0   0.0  0.0      0.0       1.0     0.0    1.0    0.0  23.0     4.0   \n",
       "5390    5.0   0.0  1.0      0.0       0.0     1.0    0.0    0.0  27.0     0.0   \n",
       "860     0.0   2.0  0.0      1.0       0.0     1.0    0.0    0.0  22.0     0.0   \n",
       "7270    2.0   0.0  1.0      0.0       0.0     1.0    1.0    0.0  28.0     0.0   \n",
       "\n",
       "          tenure  hours  wks_work  \n",
       "9133    2.000000   40.0      74.0  \n",
       "12033  15.083333   40.0      69.0  \n",
       "11515   1.416667   40.0      58.0  \n",
       "7077    1.416667   40.0      51.0  \n",
       "1886   10.000000   35.0      54.0  \n",
       "...          ...    ...       ...  \n",
       "5191    4.250000   40.0      52.0  \n",
       "13418   1.000000   40.0      48.0  \n",
       "5390    4.416667   40.0      58.0  \n",
       "860     2.666667   38.0      52.0  \n",
       "7270    2.666667   49.0      48.0  \n",
       "\n",
       "[10761 rows x 13 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: define DML model with double LASSO\n",
    "\n",
    "from econml.dml import  LinearDML\n",
    "from sklearn.linear_model import LassoCV, LogisticRegressionCV\n",
    "\n",
    "# LinearDML: https://econml.azurewebsites.net/_autosummary/econml.dml.LinearDML.html\n",
    "lasso_mod = LassoCV(cv=5)\n",
    "lasso_mod.fit(X_train,y_train)\n",
    "log_mod = LogisticRegressionCV(cv=5)\n",
    "log_mod.fit(X_cat,X_cat['union'])\n",
    "est = LinearDML(model_y=lasso_mod,\n",
    "                model_t=log_mod,    \n",
    "                discrete_treatment=False,\n",
    "                linear_first_stages=True,\n",
    "                cv=5)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       year  race  msp  nev_mar  not_smsa  c_city  south   age  wks_ue  \\\n",
      "9133   11.0   0.0  0.0      0.0       0.0     0.0    1.0  40.0     0.0   \n",
      "12033  11.0   0.0  0.0      0.0       0.0     1.0    1.0  35.0     0.0   \n",
      "11515   7.0   2.0  1.0      0.0       0.0     0.0    1.0  31.0    40.0   \n",
      "7077    3.0   0.0  0.0      1.0       0.0     1.0    1.0  20.0     0.0   \n",
      "1886    5.0   2.0  1.0      0.0       0.0     0.0    0.0  28.0     0.0   \n",
      "...     ...   ...  ...      ...       ...     ...    ...   ...     ...   \n",
      "5191    2.0   2.0  1.0      0.0       0.0     1.0    0.0  24.0     0.0   \n",
      "13418   1.0   0.0  0.0      0.0       1.0     0.0    1.0  23.0     4.0   \n",
      "5390    5.0   0.0  1.0      0.0       0.0     1.0    0.0  27.0     0.0   \n",
      "860     0.0   2.0  0.0      1.0       0.0     1.0    0.0  22.0     0.0   \n",
      "7270    2.0   0.0  1.0      0.0       0.0     1.0    1.0  28.0     0.0   \n",
      "\n",
      "          tenure  hours  wks_work  \n",
      "9133    2.000000   40.0      74.0  \n",
      "12033  15.083333   40.0      69.0  \n",
      "11515   1.416667   40.0      58.0  \n",
      "7077    1.416667   40.0      51.0  \n",
      "1886   10.000000   35.0      54.0  \n",
      "...          ...    ...       ...  \n",
      "5191    4.250000   40.0      52.0  \n",
      "13418   1.000000   40.0      48.0  \n",
      "5390    4.416667   40.0      58.0  \n",
      "860     2.666667   38.0      52.0  \n",
      "7270    2.666667   49.0      48.0  \n",
      "\n",
      "[10761 rows x 12 columns]\n",
      "       union\n",
      "9133     0.0\n",
      "12033    0.0\n",
      "11515    0.0\n",
      "7077     1.0\n",
      "1886     1.0\n",
      "...      ...\n",
      "5191     1.0\n",
      "13418    0.0\n",
      "5390     0.0\n",
      "860      0.0\n",
      "7270     0.0\n",
      "\n",
      "[10761 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<econml.dml.dml.LinearDML at 0x12f8adf50>"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T_train = X_train[['union']] \n",
    "X_train = X_train.drop(columns=['union'])\n",
    "\n",
    "print(X_train)\n",
    "print(T_train)\n",
    "est.fit(Y=y_train,X=X_train,T=T_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Coefficient Results</caption>\n",
       "<tr>\n",
       "      <td></td>     <th>point_estimate</th> <th>stderr</th>  <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>year</th>          <td>-0.0</td>       <td>0.005</td> <td>-0.033</td>  <td>0.974</td>  <td>-0.009</td>    <td>0.009</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>race</th>          <td>-0.03</td>      <td>0.009</td> <td>-3.194</td>  <td>0.001</td>  <td>-0.048</td>   <td>-0.011</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>msp</th>           <td>0.027</td>      <td>0.021</td>  <td>1.251</td>  <td>0.211</td>  <td>-0.015</td>    <td>0.069</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>nev_mar</th>       <td>0.02</td>       <td>0.026</td>  <td>0.774</td>  <td>0.439</td>  <td>-0.031</td>    <td>0.071</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>not_smsa</th>      <td>0.028</td>      <td>0.02</td>   <td>1.406</td>  <td>0.16</td>   <td>-0.011</td>    <td>0.066</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>c_city</th>       <td>-0.025</td>      <td>0.019</td>  <td>-1.34</td>  <td>0.18</td>   <td>-0.062</td>    <td>0.012</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>south</th>        <td>-0.044</td>      <td>0.019</td> <td>-2.314</td>  <td>0.021</td>  <td>-0.081</td>   <td>-0.007</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>age</th>           <td>0.003</td>      <td>0.003</td>  <td>1.283</td>  <td>0.199</td>  <td>-0.002</td>    <td>0.009</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wks_ue</th>        <td>-0.0</td>       <td>0.002</td> <td>-0.115</td>  <td>0.908</td>  <td>-0.003</td>    <td>0.003</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tenure</th>       <td>-0.003</td>      <td>0.002</td> <td>-1.511</td>  <td>0.131</td>  <td>-0.008</td>    <td>0.001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hours</th>        <td>-0.004</td>      <td>0.001</td> <td>-2.731</td>  <td>0.006</td>  <td>-0.006</td>   <td>-0.001</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>wks_work</th>      <td>-0.0</td>        <td>0.0</td>  <td>-0.972</td>  <td>0.331</td>  <td>-0.001</td>     <td>0.0</td>  \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<caption>CATE Intercept Results</caption>\n",
       "<tr>\n",
       "         <td></td>        <th>point_estimate</th> <th>stderr</th> <th>zstat</th> <th>pvalue</th> <th>ci_lower</th> <th>ci_upper</th>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>cate_intercept</th>      <td>0.238</td>      <td>0.084</td> <td>2.854</td>  <td>0.004</td>   <td>0.075</td>    <td>0.402</td> \n",
       "</tr>\n",
       "</table><br/><br/><sub>A linear parametric conditional average treatment effect (CATE) model was fitted:<br/>$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$<br/>where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:<br/>$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$<br/>Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>"
      ],
      "text/plain": [
       "<class 'econml.utilities.Summary'>\n",
       "\"\"\"\n",
       "                     Coefficient Results                      \n",
       "==============================================================\n",
       "         point_estimate stderr zstat  pvalue ci_lower ci_upper\n",
       "--------------------------------------------------------------\n",
       "year               -0.0  0.005 -0.033  0.974   -0.009    0.009\n",
       "race              -0.03  0.009 -3.194  0.001   -0.048   -0.011\n",
       "msp               0.027  0.021  1.251  0.211   -0.015    0.069\n",
       "nev_mar            0.02  0.026  0.774  0.439   -0.031    0.071\n",
       "not_smsa          0.028   0.02  1.406   0.16   -0.011    0.066\n",
       "c_city           -0.025  0.019  -1.34   0.18   -0.062    0.012\n",
       "south            -0.044  0.019 -2.314  0.021   -0.081   -0.007\n",
       "age               0.003  0.003  1.283  0.199   -0.002    0.009\n",
       "wks_ue             -0.0  0.002 -0.115  0.908   -0.003    0.003\n",
       "tenure           -0.003  0.002 -1.511  0.131   -0.008    0.001\n",
       "hours            -0.004  0.001 -2.731  0.006   -0.006   -0.001\n",
       "wks_work           -0.0    0.0 -0.972  0.331   -0.001      0.0\n",
       "                       CATE Intercept Results                      \n",
       "===================================================================\n",
       "               point_estimate stderr zstat pvalue ci_lower ci_upper\n",
       "-------------------------------------------------------------------\n",
       "cate_intercept          0.238  0.084 2.854  0.004    0.075    0.402\n",
       "-------------------------------------------------------------------\n",
       "\n",
       "<sub>A linear parametric conditional average treatment effect (CATE) model was fitted:\n",
       "$Y = \\Theta(X)\\cdot T + g(X, W) + \\epsilon$\n",
       "where for every outcome $i$ and treatment $j$ the CATE $\\Theta_{ij}(X)$ has the form:\n",
       "$\\Theta_{ij}(X) = X' coef_{ij} + cate\\_intercept_{ij}$\n",
       "Coefficient Results table portrays the $coef_{ij}$ parameter vector for each outcome $i$ and treatment $j$. Intercept Results table portrays the $cate\\_intercept_{ij}$ parameter.</sub>\n",
       "\"\"\""
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: display a summary\n",
    "est.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compare the estimates form this and the previous regression. How do these change?**\n",
    "The previous estimate produced the following result: coefficient = 0.2502, r^2 =.052, t = 27.238. This means that while the union status is a weak predictor, the signficance of the result means that there is a relationship between the two variables. \n",
    "\n",
    "This regression produced the following result: coefficient .228, stderr .009, tstat 2.699. Because the standard error is so low, this means that the new model predicts the ln(wage) very accurately. This is likely due to the different approach to the regression. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Interpret the coefficient from the double ml approach. Can it be interpreted as causal?**\n",
    "Yes, it can be interpreted as causal. The coefficient of .228 means that ln(wage) is predicted to increase by .194 as a result of being in a union. It can be interpreted as causual because of the removed observed confounders. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Heterogenous Treatment Effects with double Lasso\n",
    "\n",
    "This exercise will be a simple extension of exercise 1. We just want to estimate a CausalForestDML model where we can analyze heterogeneous treatment effects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CausalForestDML: https://econml.azurewebsites.net/_autosummary/econml.dml.CausalForestDML.html\n",
    "from econml.dml import CausalForestDML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: define the model. check the documentation, you might need to specify less things than you think...\n",
    "est2 = CausalForestDML()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    }
   ],
   "source": [
    "# TODO: tune the model\n",
    "est2 = est2.tune(Y=y_train,T=T_train,X=X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       union\n",
      "9133     0.0\n",
      "12033    0.0\n",
      "11515    0.0\n",
      "7077     1.0\n",
      "1886     1.0\n",
      "...      ...\n",
      "5191     1.0\n",
      "13418    0.0\n",
      "5390     0.0\n",
      "860      0.0\n",
      "7270     0.0\n",
      "\n",
      "[10761 rows x 1 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<econml.dml.causal_forest.CausalForestDML at 0x12f985c90>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: fit the model\n",
    "est2.fit(y_train,T_train,X=X_train,cache_values=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population summary of CATE predictions on Training Data\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doubly Robust ATE on Training Data Results:  Doubly Robust ATE calculation on training data is available only on discrete treatments!\n",
      "Doubly Robust ATT on Training Data Results:  Doubly Robust ATT calculation on training data is available only on discrete treatments!\n",
      "               Uncertainty of Mean Point Estimate              \n",
      "===============================================================\n",
      "mean_point stderr_mean zstat pvalue ci_mean_lower ci_mean_upper\n",
      "---------------------------------------------------------------\n",
      "     0.173        0.11  1.57  0.116        -0.043         0.389\n",
      "      Distribution of Point Estimate     \n",
      "=========================================\n",
      "std_point pct_point_lower pct_point_upper\n",
      "-----------------------------------------\n",
      "    0.116           0.007           0.465\n",
      "     Total Variance of Point Estimate     \n",
      "==========================================\n",
      "stderr_point ci_point_lower ci_point_upper\n",
      "------------------------------------------\n",
      "        0.16         -0.087          0.563\n",
      "------------------------------------------\n",
      "\n",
      "Note: The stderr_mean is a conservative upper bound.\n"
     ]
    }
   ],
   "source": [
    "# TODO: display summary\n",
    "summ = est2.summary()\n",
    "print(summ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([<matplotlib.axis.XTick at 0x12fa2db10>,\n",
       "  <matplotlib.axis.XTick at 0x12f99cb10>,\n",
       "  <matplotlib.axis.XTick at 0x12fa30dd0>,\n",
       "  <matplotlib.axis.XTick at 0x12fa51fd0>,\n",
       "  <matplotlib.axis.XTick at 0x12fa54990>,\n",
       "  <matplotlib.axis.XTick at 0x12fa57310>,\n",
       "  <matplotlib.axis.XTick at 0x12fa599d0>,\n",
       "  <matplotlib.axis.XTick at 0x12fa53050>,\n",
       "  <matplotlib.axis.XTick at 0x12faacd10>,\n",
       "  <matplotlib.axis.XTick at 0x12faaf010>,\n",
       "  <matplotlib.axis.XTick at 0x12fab13d0>,\n",
       "  <matplotlib.axis.XTick at 0x12fab3990>],\n",
       " [Text(0, 0, 'year'),\n",
       "  Text(1, 0, 'race'),\n",
       "  Text(2, 0, 'msp'),\n",
       "  Text(3, 0, 'nev_mar'),\n",
       "  Text(4, 0, 'not_smsa'),\n",
       "  Text(5, 0, 'c_city'),\n",
       "  Text(6, 0, 'south'),\n",
       "  Text(7, 0, 'age'),\n",
       "  Text(8, 0, 'wks_ue'),\n",
       "  Text(9, 0, 'tenure'),\n",
       "  Text(10, 0, 'hours'),\n",
       "  Text(11, 0, 'wks_work')])"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# TODO: visualize the feature importance\n",
    "from matplotlib import pyplot as plt\n",
    "feature_importance = est2.feature_importances_\n",
    "feat_names = X_train.columns\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(len(feature_importance)), feature_importance)\n",
    "plt.xticks(range(len(feat_names)), feat_names, rotation=90)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
